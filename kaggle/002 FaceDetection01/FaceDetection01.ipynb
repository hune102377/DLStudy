{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고자료 : https://suy379.tistory.com/90?category=937254  \n",
    "- 이번 챕터에서 배울 수 있는 점\n",
    "    * 이미지, 동영상 데이터를 불러오는 방법\n",
    "    * 동영상을 이미지로 나눠서 저장하는 방법\n",
    "    * 이미지, 동영상 속에서 사람의 얼굴을 검출하는 방법\n",
    "    * 원본 영상에서 사람 얼굴을 검출하고 짧은 타임랩스 영상 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenCV 라이브러리 : 이미지 및 동영상 데이터 다루는 라이브러리**  \n",
    "**dlib 라이브러리 : 얼굴 안면 인식을 가능하게 하는 라이브러리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. 데이터 불러오기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 이미지 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[중요 메서드]**  \n",
    "\n",
    "\n",
    "    - cv2.imread(path) : path로부터 이미지 파일을 읽어온다.\n",
    "    - cv2.imshow('file', file) : 파일명을 통해 이미지 파일을 연다\n",
    "    - cv2.waitKey(숫자) : 숫자에 지정한 밀리초 만큼 이미지를 표시한다. 단, 0으로 지정하면 사용자가 창을 닫아야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # 이미지 파일을 다루는 OpenCV 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이미지 파일읽어보기\n",
    "# img = cv2.imread('./data/img/01.png')\n",
    "# # 이미지의 길이와 넓이 저장\n",
    "# height, width = img.shape[:2]\n",
    "\n",
    "# print('img width :', width)\n",
    "# print('img height :', height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이미지 확인\n",
    "# cv2.imshow('img', img)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 동영상 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영상 출처  \n",
    "mov01 : https://www.youtube.com/watch?v=bp6hhq8DdgU  \n",
    "mov02 : https://www.youtube.com/watch?v=RICA_Su1blM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[중요 메서드]**\n",
    "\n",
    "    - cap = cv2.VideoCapture(path) : path로부터 동영상 파일을 불러와 'cap'으로 저장\n",
    "    - cap.read() : 영상 정보를 읽어온다.\n",
    "    - cap.get() : 영상 정보를 읽어오면서 옵션으로 특정 정보만 뽑을 수 있다.\n",
    "        * cv2.CAP_PROP_FRAME_WIDTH : width 정보\n",
    "        * cv2.CAP_PROP_FRAME_HEIGHT : height 정보\n",
    "        * cv2.CAP_PROP_FRAME_COUNT : 영상 총 프레임 수 정보\n",
    "        * cv2.CAP_PROP_FPS : 영상 fps 값\n",
    "    - cv2.imshow('file', 'file) : 영상 파일을 연다.\n",
    "    - cv2.waitKey(숫자) : 숫자에 지정한 밀리초(ms) 만큼 영상을 표시\n",
    "    - cv2.destroyAllWindows() : 모든 열려있는 창(영상, 이미지)를 닫는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 동영상 불러오기\n",
    "# cap = cv2.VideoCapture('./data/mov/mov01.mp4')\n",
    "# cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 동영상 정보\n",
    "# width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "# height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "# count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# print('가로 :', str(width))\n",
    "# print('세로 :', str(height))\n",
    "# print('총 프레임 수 :', str(count))\n",
    "# print('FPS :', str(fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 동영상 - 출력\n",
    "# while(cap.isOpened()) :\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret :\n",
    "#         cv2.imshow('frame', frame)\n",
    "#     # 'q'키를 누르면 영상 종료\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q') :\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 동영상을 이미지로 나누고 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture('./data/mov/mov01.mp4')\n",
    "# num = 0\n",
    "\n",
    "# while(cap.isOpened()) :\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret :\n",
    "#         cv2.imshow('frame', frame)\n",
    "#         # 이미지의 각 이름을 자동으로 지정\n",
    "#         path ='./data/snapshot/snap01/snapshot_' + str(num) + '.jpg'\n",
    "#         cv2.imwrite(path, frame)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q') :\n",
    "#         break\n",
    "#     num += 1\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. 이미지에서 얼굴 인식**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 이미지 속 사람 검출 (HOG-SVMDectector 모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[주요 메서드]**\n",
    "\n",
    "- hog = cv2.HOGDescriptor() : HOG 객체 만들기\n",
    "- hog.setSVMDetector(HOGDescriptor_getDefaultPeopleDetector()) : SVMDetector 모델 지정하기\n",
    "- hogParams = {} : 파라미터 지정하기\n",
    "\n",
    "- cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) : 흑백으로 변환\n",
    "- hog.detectMultiScale(객체,hogParams) : 흑백으로 변환한 객체와 파라미터를 input으로 넣고 그 위치정보를 반환\n",
    "- cv2.rectangel(img, pt1, pt2, color, thickness) : 검출한 사람 주위에 사각형을 그리는 메서드\n",
    "    * pt1 : 시작점 좌표\n",
    "    * pt2 : 종료점 좌표\n",
    "    * color : 사각형 색\n",
    "    * thickness : 사각형 선 굵기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 객체 생성\n",
    "# hog = cv2.HOGDescriptor()\n",
    "# # 모델 지정\n",
    "# hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "# # 파라미터 설정\n",
    "# hogParams = {'winStride' : (8, 8), 'padding' : (32,32), 'scale' : 1.05, 'hitThreshold' : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이미지 읽기\n",
    "# img = cv2.imread('./data/img/01.png')\n",
    "# # 흑백변화\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# # 사람 검출\n",
    "# human, r = hog.detectMultiScale(gray, **hogParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (len(human) > 0) :\n",
    "#     for (x, y, w, h) in human :\n",
    "#         cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "# cv2.imshow('img', img)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 이미지 속 사람 얼굴 검출 (CascadeClassifier 모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CascadeClassifier 모델의 경우 언굴 검출에서 전통적인 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[중요 메서드]**\n",
    "\n",
    "- cascade = cv2.CacadeClassifier(file) : CascadeClassifier 모델 지정  \n",
    "\n",
    "- cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) : 흑백으로 변환하기  \n",
    "- cascade.detectMultiScale(객체, size) : 앞서 흑백으로 변환한 객체와 size를 통해 사람 얼굴을 검출하고 위치정보 반환\n",
    "- cv2.rectangle(img, pt1, pt2, color, thickness) : Tech 84에서 설명한 것과 동일\n",
    "\n",
    "- cv2.namedWindow('file', cv2.WINDOW_NORMAL_) : 'file'이라는 이름으로 창을 생성함\n",
    "- cv2.waitKey(숫자) : 지정한 시간만큼 이미지 or 영상 파을 띄운다\n",
    "- cv2.destroyAllWindows() : 모든 창 닫기\n",
    "- cv2.destroyWindow('file') : 'file' 창만 닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 준비\n",
    "cascade_file = 'haarcascade_frontalface_alt.xml'\n",
    "cascade = cv2.CascadeClassifier(cascade_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\Desktop\\File\\DLStudy\\kaggle\\002 FaceDetection01\\FaceDetection01.ipynb 셀 27\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/File/DLStudy/kaggle/002%20FaceDetection01/FaceDetection01.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39m./data/img/01.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/File/DLStudy/kaggle/002%20FaceDetection01/FaceDetection01.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/File/DLStudy/kaggle/002%20FaceDetection01/FaceDetection01.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m face_list \u001b[39m=\u001b[39m cascade\u001b[39m.\u001b[39;49mdetectMultiScale(gray, minSize \u001b[39m=\u001b[39;49m (\u001b[39m50\u001b[39;49m, \u001b[39m50\u001b[39;49m))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "# 검출하기\n",
    "img = cv2.imread('./data/img/01.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "face_list = cascade.detectMultiScale(gray, minSize = (50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\Desktop\\File\\DLStudy\\kaggle\\002 FaceDetection01\\FaceDetection01.ipynb 셀 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/File/DLStudy/kaggle/002%20FaceDetection01/FaceDetection01.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m (x, y, w, h) \u001b[39min\u001b[39;00m face_list :\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/File/DLStudy/kaggle/002%20FaceDetection01/FaceDetection01.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     color \u001b[39m=\u001b[39m (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m , \u001b[39m255\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/File/DLStudy/kaggle/002%20FaceDetection01/FaceDetection01.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     pen_w \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'face_list' is not defined"
     ]
    }
   ],
   "source": [
    "for (x, y, w, h) in face_list :\n",
    "    color = (0, 0 , 255)\n",
    "    pen_w = 3\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), color, thickness = pen_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('img', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('img', img)\n",
    "cv2.imwrite('temp.png', img)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
