{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **인공지능을 위한 기초수학**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1. 행렬과 빅데이터 분석**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.0 Big Picture (기초 선형대수학 개념의 구성)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Vector : 방향과 크기를 모두 포함하는 물리량  \n",
    "\n",
    "- Vector Norm : Vector의 크기(manitude) 또는 길이(length)를 측정하는 방법\n",
    "    * $L_1 norm$ : 맨해튼 놈(Manhattan norm) 또는 택시 놈(Taxi norm), 가로 세로 벡터의 합(모든 성분의 절대값의 총합)\n",
    "    * $L_2 norm$ : 유클리드 놈(Euclidean norm), 출발점에서 도착점까지의 거리를 직선거리로 측정(모든 성분의 제곱의 루트)\n",
    "    * $L_∞ norm$ : 최대 놈(Max norm), 모든 성분들의 절대값 중 가장 큰 값\n",
    "    * $L_0 norm$ : 모든 성분들 중에서 0이 아닌 것의 갯수로 계산  \n",
    "\n",
    "- 벡터의 내적(Euclidean inner product, dot product) : $x*y = x_1y_1 + x_2y_2+ ... + x_ny_n$, 딥러닝 설계시 노드의 합이 내적으로 계산이 적용된다  \n",
    "\n",
    "- 벡터의 공간(vector space) : 공집합이 아닌 임의의 집합($V$)에 덧셈(vector addition)($+$)과 스칼라 배(scaler multiplication, $⋅$)의 두 연산이 정의되고,  \n",
    " 2개의 기본성질(두 연산에 대해서 닫혀있다)과 8개의 연산 성징을 만족하면 ($V, +, ⋅$)가 벡터공간을 이룬다고 한다. \n",
    "\n",
    " - 부분공간 : 부분공간은 벡터공간의 부분집합이면서 그 자체로 벡터공간이 되는 경우를 말한다\n",
    "\n",
    " - 2 step 부분공간 test : $W$가 $V$의 부분공간이 되는지 확인하려면 다음의 두가지 테스트를 만족하면 된다.\n",
    "    - (1) $u + v,  ∀u, v ∈ W$\n",
    "    - (2) $α u ∈ W,  ∀u ∈ W, α ∈ R$\n",
    "\n",
    " - 일차결합 : 학 벡터공간 U에 스칼라 α를 일차결합하는 경우 $α_1u_1 + a_2u_2 + ... + a_ku_k$\n",
    "\n",
    " - 일차독립 : $U = {u_1, u_2, .., u_k}$ 에 대하여 $α_1u_1 + α_2u_2 + ... α_ku_k = 0 => α_1 = a_2 = ... = a_k = 0$\n",
    "\n",
    " - 일차종속 : 일차독립이 아니면 일차종속(linearly dependent)이라 한다\n",
    "\n",
    " - 벡터공간의 기저(basis) : 일차독립이며 $<B> = V$인 경우 $B$가 $V$의 기저라고 한다\n",
    "\n",
    " - 벡터공간의 차원 : $B$가 $V$의 기저라 할 때 $V$의 차원은 $dim V = ㅣBㅣ$\n",
    "\n",
    " - 행공간(row space) : 행벡터들의 일차결합 전체의 집합\n",
    "\n",
    " - 열공간(column space) : 열벡터들의 일차결합 전체의 집합을 열공간\n",
    "\n",
    " - 계수(rank) : 행공간(열공간)의 차원을 행렬의 계수라 한다\n",
    "\n",
    " - 초평면(hyperplane) :\n",
    "\n",
    " - 정사영 :\n",
    "\n",
    " - 행렬의 고윳값과 고유벡터 : $A$가$n$차의 정사각행렬일 때, $det() = 0$\n",
    "\n",
    " - 행렬의 대각화 : \n",
    "\n",
    " - SVD\n",
    "\n",
    " - 차원축소와 변수추출\n",
    " \n",
    " - 주축정리\n",
    "\n",
    " - 고윳값 분해\n",
    "\n",
    " - PCA\n",
    "\n",
    " - 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참조 : https://bskyvision.com/entry/%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99-%EB%86%88norm%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80  \n",
    "참조 : https://www.aitimes.kr/news/articleView.html?idxno=17314  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.1 벡터**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.1.1 벡터(Vector)**\n",
    "\n",
    "- 스칼라(scalar) : 길이, 넓이, 질량, 온도 - 크기만 주어진 정보  \n",
    "\n",
    "- 벡터(vector) : 속도, 위치이동, 힘 - 크기와 방향이 포함된 정보\n",
    "\n",
    "- vector의 경우 화살표로 표현 가능\n",
    "\n",
    "- 시작점과 끝점이 같아서 크기가 0인 vector를 영벡터라 한다. (영벡터의 방향은 임의의 방향으로 한다)\n",
    "\n",
    "- n-dimensional vector(n차원 벡터) : n개의 실수의 순서조라 하며 이 때 내부의 실수를 해당 벡터의 성분이라고 한다\n",
    "\n",
    "- 벡터의 상등 : 벡터 $x$ $=$ 벡터 $y$ 인 경우 \n",
    "\n",
    "- 벡터 합과 스칼라배\n",
    "\n",
    "- 음벡터 : $-x$  ($x * -x=0$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.1.2 내적**  \n",
    "\n",
    "- $x$의 노름(norm, length, magnitude) : $∥x∥ = \\sqrt{x_1^2 + x_2^2 + ... +x_n^2}$\n",
    "\n",
    "- $x$와 $y$의 거리 : $∥x-y∥ = \\sqrt{(x_1-y_1)^2 + (x_2-y_2)^2 + ... +(x_n-y_n)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.1.3 정사영**\n",
    "\n",
    "![img_01](./img/01.png)  \n",
    "\n",
    "- $p$를 $x$ 위로의 $y$의 정사영이라 하고 $proj_xy=p$  \n",
    "$w$를 $x$에 직교인 $y$의 벡터성분이라고 한다\n",
    "\n",
    "- $proj_xy=tx$ 여기서 $t = (y * x \\over(∥x∥^2))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.2 선형엽립방정식**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.2.1 선형연립방정식**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $a_{11}x_1 + a_{12}x_2 + ... + a_{1n}x_n = b_1 $  \n",
    "$a_{21}x_1 + a_{22}x_2 + ... + a_{2n}x_n = b_2 $  \n",
    "$...$  \n",
    "$a_{m1}x_1 + a_{m2}x_2 + ... + a_{mn}x_n = b_m $  \n",
    "등 선형방정식의 모임으로 나타나는 식을 선형연립방정식(system of linear equations)이라고 하며  \n",
    "$b_m$이 일 경우를 동차선형엽립방정식(동차선형방정식시스템)이라고 한다.\n",
    "\n",
    "- 미지수 $x_1,x_2, ... x_n$에 어떤 수 $s_1,s_2, ... s_n$을 각각 대입했을 때 각 방정식이 모두 성립하면 $s_1,s_2, ... s_n$을 선형연립방정식의 해(soulution)라고 한다.\n",
    "    * 선형연립방정식의 해가 존재하는 경우 : 일관된(consistent) 연립방정식\n",
    "    * 해가 존재하지 않는 경우 : 일관되지 않은(inconsistent) 연립방정식\n",
    "\n",
    "- 선형연립방정식  \n",
    "$a_{11}x_1 + a_{12}x_2 + ... + a_{1n}x_n = b_1 $  \n",
    "$a_{21}x_1 + a_{22}x_2 + ... + a_{2n}x_n = b_2 $  \n",
    "$...$  \n",
    "$a_{m1}x_1 + a_{m2}x_2 + ... + a_{mn}x_n = b_m $  \n",
    "\n",
    "![img02](./img/02.png)  \n",
    "으로 표현할 수 있으며  \n",
    "$Ax = b$\n",
    "이 때 행렬 $A$를 선형엽립방정식의 계수행렬(coefficient matrix)이라 한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.2.2 Gauss 소거법과 Gauss-Jordan 소거법**\n",
    "\n",
    "- 선형연립방정식의 풀이 : **소거법**  \n",
    "\n",
    "- 소거법에서 행한 연산 : 선형연립방정식의 해집합을 바꾸지 않는다.  \n",
    "(1) 두 식을 교환한다.  \n",
    "(2) 한 식에 0 아닌 실수를 곱한다.   \n",
    "(3) 한 식에 0 아닌 실수배를 하여 다른 식에 더한다  \n",
    "이를 기본행 연산(ERO, Elementary Row Operations) 이라 한다.\n",
    "\n",
    "- 행 사다리꼴(REF)  \n",
    "(1) 성분이 모두 0인 행이 존재하면 그 행은 행렬의 맨 아래에 위치한다  \n",
    "(2) 각 행에서 처음으로 나타나는 0이 아닌 성분은 1이며 그 행의 선행성분이라 한다  \n",
    "(3) $i$ 행과 ($i+1$) 행 모두에 선행성분이 존재하면 ($i+1$)행의 선행성분은 $i$행의 선행성분보다 오른쪽에 위치한다.\n",
    "(4) 선행성분을 포함하는 열의 선행선분 외의 성분은 모두 0이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**정리**\n",
    "- **Gauss 소거법** : 선형연립방정식의 첨가행렬을 REF로 변형하여 푸는 방법\n",
    "- **Gauss-Jorda 소거법** : 선형연립방정식의 첨가행렬을 RREF로 변형하여 푸는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.3 행렬과 행렬식**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.3.1 행렬 연산**\n",
    "\n",
    "- 합과 스칼라 배($kA$)\n",
    "    - 행렬 덧셈이 정의되려면 두 행렬의 크기가 같아야 한다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
